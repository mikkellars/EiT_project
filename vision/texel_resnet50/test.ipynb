{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document for evaluating on full images using trained resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DATASET_PATH = Path(\"/home/mikkel/Documents/experts_in_teams_proj/vision/data/fence_data/texel_data/categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the dataloader with full images each cropped to texel/no-texel size by making a custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAlbumentationsTransform(Transform):\n",
    "    \"\"\"Class for applying the transformations on the images\n",
    "    \"\"\"\n",
    "    def __init__(self, aug): \n",
    "        self.aug = aug\n",
    "           \n",
    "    def encodes(self, img: PILImage):\n",
    "        aug_img = self.aug(image=np.array(img))['image']\n",
    "        return PILImage.create(aug_img)\n",
    "\n",
    "trans = A.Compose([\n",
    "    A.HorizontalFlip(p=0.25),\n",
    "    A.VerticalFlip(p=0.25),\n",
    "    A.RandomBrightnessContrast(p=1),    \n",
    "    A.RandomGamma(p=1),    \n",
    "    A.CLAHE(p=1),\n",
    "    \n",
    "])\n",
    "\n",
    "tfm = ImageAlbumentationsTransform(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fname):\n",
    "    return 'texel' if 'true' in str(fname) else \"no texel\"\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=label_func,\n",
    "    item_tfms=[ToTensor, tfm],\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=100),\n",
    "    batch_tfms = [IntToFloatTensor, Normalize.from_stats(*imagenet_stats)],\n",
    ")\n",
    "\n",
    "dls = dblock.dataloaders(DATASET_PATH, bs=12, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading trained parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f7c51307310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = cnn_learner(dls, resnet50, metrics=accuracy, model_dir=\"/home/mikkel/Documents/experts_in_teams_proj/vision/texel_resnet50/models\")\n",
    "learn.load(\"/home/mikkel/Documents/experts_in_teams_proj/vision/texel_resnet50/models/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[0], stepSize):\n",
    "        for x in range(0, image.shape[1], stepSize):\n",
    "            # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = list()\n",
    "\n",
    "winW = 32\n",
    "winH = 32\n",
    "ori_img = cv2.imread('/home/mikkel/Documents/experts_in_teams_proj/vision/data/lorenz-fence-inspection-examples/images/Eskild_fig_3_16.jpg')\n",
    "resized = cv2.resize(ori_img, (1280, 1280))\n",
    "for (x, y, window) in sliding_window(resized, stepSize=32, windowSize=(winW, winH)):\n",
    "    # if the window does not meet our desired window size, ignore it\n",
    "    if window.shape[0] != winH or window.shape[1] != winW:\n",
    "        continue\n",
    "    # THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A\n",
    "    # MACHINE LEARNING CLASSIFIER TO CLASSIFY THE CONTENTS OF THE\n",
    "    # WINDOW\n",
    "    # since we do not have a classifier, we'll just draw the window\n",
    "    patch = resized[y:y+winH, x:x+winW]\n",
    "    patches.append(PILImage.create(patch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running prediction for image: 100%|██████████| 1600/1600 [00:13<00:00, 115.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trans=transforms.Compose([transforms.Resize(128),\n",
    "                          transforms.ToTensor(),\n",
    "                          transforms.Normalize(*imagenet_stats)\n",
    "                          ]\n",
    ")\n",
    "\n",
    "model = learn.model.to(device)\n",
    "have_texel = list()\n",
    "loop = tqdm(patches)\n",
    "loop.set_description(\"Running prediction for image\")\n",
    "for i, patch in enumerate(loop):\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        patch = trans(patch)\n",
    "        patch = torch.unsqueeze(patch, dim=0)    \n",
    "        p = learn.model(patch.to('cuda'))\n",
    "        if torch.argmax(p).item() == 1: # 1 indx is texel\n",
    "            have_texel.append(i)\n",
    "print(len(have_texel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, patch in enumerate(patches):\n",
    "    cv2.imshow(\"t\", np.array(patches[i])) \n",
    "    btn_pressed = cv2.waitKey()  \n",
    "    if btn_pressed == 113:\n",
    "        cv2.destroyAllWindows()  \n",
    "        break\n",
    "    cv2.waitKey(0)  \n",
    "    if i in have_texel:\n",
    "        cv2.imshow(\"t\", np.array(patches[i])) \n",
    "        btn_pressed = cv2.waitKey()  \n",
    "        \n",
    "        cv2.waitKey(0)  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
